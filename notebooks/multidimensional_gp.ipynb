{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional GP\n",
    "\n",
    "Until now, our examples have been of 1-dimensional Gaussian processes, where there is just a single predictor variable thought to have a non-linear relationship to the outcome. Let's look at a real-world dataset that involves two predictors. We will use the famous **Walker Lake dataset (Isaaks & Srivistava 1989)** that involves spatial sampling of minerals and other variables over space. The data consist of two spatial coordinates and three measured outcomes. The outcomes are anonymously labeled as U, V (continuous variables, such as concentrarion) and T (discrete variable, such as the presence of a particular element). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walker_data = pd.read_table('../data/walker.txt', sep='\\s+', index_col=0, skiprows=8, header=None, \n",
    "              names=['ID', 'Xloc', 'Yloc', 'V', 'U', 'T'])\n",
    "walker_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples are taken regularly over a coarse grid across the entire area, and then irregularly over portions of the area, presumably where there were positive samples on the coarser grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 40\n",
    "x1, x2 = np.meshgrid(np.linspace(0,300,nx), np.linspace(0,300,nx))\n",
    "X = np.concatenate([x1.reshape(nx*nx, 1), x2.reshape(nx*nx, 1)], 1)\n",
    "\n",
    "X_obs = walker_data[['Xloc', 'Yloc']].values\n",
    "y_obs = walker_data.V.values\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.scatter(X_obs[:,0], X_obs[:,1], s=50, c=y_obs, marker='s', cmap=plt.cm.viridis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a sparse grid of inducing points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = 15\n",
    "xu1, xu2 = np.meshgrid(np.linspace(0, 300, nd), np.linspace(0, 300, nd))\n",
    "Xu = np.concatenate([xu1.reshape(nd*nd, 1), xu2.reshape(nd*nd, 1)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as spatial_model:\n",
    "    \n",
    "    l = pm.HalfCauchy(\"l\", beta=3, shape=(2,))\n",
    "    sf2 = pm.HalfCauchy(\"sf2\", beta=3)\n",
    "    sn2 = pm.HalfCauchy(\"sn2\", beta=3)\n",
    "\n",
    "    K = pm.gp.cov.ExpQuad(2, l) * sf2**2\n",
    "    \n",
    "    gp_spatial = pm.gp.MarginalSparse(cov_func=K, approx=\"FITC\")\n",
    "    obs = gp_spatial.marginal_likelihood(\"obs\", X=X_obs, Xu=Xu, y=y_obs, noise=sn2)\n",
    "\n",
    "    mp = pm.find_MAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = 30\n",
    "z1, z2 = np.meshgrid(np.linspace(0, 300, nd), np.linspace(0, 300, nd))\n",
    "Z = np.concatenate([z1.reshape(nd*nd, 1), z2.reshape(nd*nd, 1)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with spatial_model:\n",
    "\n",
    "    f_pred = gp_spatial.conditional('f_pred', Z)\n",
    "    \n",
    "    samples = pm.sample_posterior_predictive([mp], vars=[f_pred], samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    ax = sns.heatmap(samples['f_pred'].mean(0).reshape(nd, nd), cmap='viridis')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/05a9210d3ea6546e14e6fcb8fd10a906"
  },
  "gist": {
   "data": {
    "description": "GP Showdown.ipynb",
    "public": true
   },
   "id": "05a9210d3ea6546e14e6fcb8fd10a906"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
